# Machine-Learning-VK-bot
## Схема работы
![alt text][logo]

## Возможности по улучшению и х100 ускорению
1. Добавить второй GPU, тогда модель Seq2Seq на PyTorch будет работать в десятки раз быстрее.
2. Архитектура легко масштабируется горизонтально. Можно добавлять tf-serving воркеры
и балансировать трафик между ними, например, через HAProxy или Envoy. Также легко масштабируются
и aiohttp воркеры.
3. Заменить HTTP на gRPC между tf-serving воркерами и воркерами aiohttp. Это позволит ускорить передачу
изображений.
4. Роутить сообщения между aiohttp воркерами и бекендом с помощью быстрой очереди, например, ZeroMQ.
5. Перевести модель PyTorch в Tensorflow с помощью ONNX и хостить её на быстром tf-serving.
6. Вертикальное масштабирование. Добавить больше GPU, CPU и тд.

[logo]: https://storage.googleapis.com/amiable-evening-221409.appspot.com/Untitled%20Diagram.jpg "Logo Title Text 2"